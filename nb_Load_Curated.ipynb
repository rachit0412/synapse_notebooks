{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Environment variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "#  Environment parameters \n",
        "env = 'td'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import pytz\n",
        "import time\n",
        "import pyodbc\n",
        "import pandas as pd\n",
        "from datetime import *\n",
        "from delta.tables import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Functions for the program"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Function to load active records of delta table to dataframe\n",
        "def load_delta_data_in_temp_views(source, source_container, storageaccount, table_name):\n",
        "    print(f\"loading the dataframe to create the temp view\")\n",
        "    source_path = f\"abfss://{source_container}@{storageaccount}.dfs.core.windows.net/{source}/data/{table_name}\"\n",
        "    df = spark.read.load(path=source_path,format=\"delta\")\n",
        "    df = df.filter(df.IsActive_Record == 'Y')\n",
        "    df.createOrReplaceTempView(f\"{table_name}\")\n",
        "    print(f\"temporary view created for the table {table_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Function to write the output of spark sql to delta table in curated layer\n",
        "def write_to_delta_table(df, source, destination_container, destination_table_name, storageaccount):\n",
        "    print(f\"-------------------------\")\n",
        "    print(f\"Writing the data to delta table\")\n",
        "    destination_path = f\"abfss://{destination_container}@{storageaccount}.dfs.core.windows.net/{source}/data/{destination_table_name}\"\n",
        "    df.write.option('path', destination_path).mode(\"overwrite\").format(\"delta\").saveAsTable(destination_table_name)\n",
        "    print(f\"Delta table created: {destination_table_name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Special blocks for temporary purpose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "path_st_mandant = f\"abfss://enriched@storageaccounttest.dfs.core.windows.net/<source_system>/data/st_mandant\"\n",
        "df_st_mandant = spark.read.format(\"delta\").option(\"header\", \"true\").load(path_st_mandant) \n",
        "##df_st_mandant = df_st_mandant.filter(df_st_mandant.IsActive_Record == 'Y')\n",
        "df_st_mandant.createOrReplaceTempView(\"st_mandant\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "path_st_wechselkurs_akt = f\"abfss://enriched@storageaccounttest.dfs.core.windows.net/<source_system>/data/st_wechselkurs_akt\"\n",
        "df_st_wechselkurs_akt = spark.read.format(\"delta\").option(\"header\", \"true\").load(path_st_wechselkurs_akt) \n",
        "##df_st_wechselkurs_akt = df_st_wechselkurs_akt.filter(df_st_wechselkurs_akt.IsActive_Record == 'Y')\n",
        "df_st_wechselkurs_akt.createOrReplaceTempView(\"st_wechselkurs_akt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Run process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Other variables assignment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "if env == 'td':\n",
        "    storageaccount = 'storageaccounttest'\n",
        "else:\n",
        "    storageaccount = 'storageaccountprod'\n",
        "\n",
        "# Source\n",
        "source = '<source_system>'\n",
        "source_container = 'enriched'\n",
        "\n",
        "# destination\n",
        "destination_container = 'curated'\n",
        "destination_table_name = '<table_name>'\n",
        "\n",
        "# Metadata path - SAP Table DD03L\n",
        "meta_path = f\"abfss://{source_container}@{storageaccount}.dfs.core.windows.net/{source}/data/dd03l\"\n",
        "\n",
        "# Keyl vault\n",
        "key_vault_name = 'KV-'+env.upper()+'WEUGDWHDATAHUB'\n",
        "ls_key_vault_name = 'ls_AzureKeyVault'\n",
        "\n",
        "# Metadata DB\n",
        "meta_server = 'tcp:sql-'+env+'-weu-GDWH-datahub.database.windows.net'\n",
        "meta_database = 'SQLDB-METADATASTOREDB'\n",
        "meta_username = 'sqlserveradmin'\n",
        "\n",
        "# get Metadata DB password\n",
        "meta_password = mssparkutils.credentials.getSecret(key_vault_name,meta_username,ls_key_vault_name) \n",
        "\n",
        "# Set timezone\n",
        "timezone = pytz.timezone('Europe/Amsterdam')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Connection to metadata table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Connect to metadata DB\n",
        "driver = '{ODBC Driver 17 for SQL Server}'\n",
        "cnxn = pyodbc.connect('DRIVER='+driver+';SERVER='+meta_server+';PORT=1433;DATABASE='+meta_database+';UID='+meta_username+';PWD='+ meta_password)\n",
        "\n",
        "# Read metadata for tables using:\n",
        "# 1) SAP Extraction Table \n",
        "\n",
        "# Logging start\n",
        "print(f\"------------LOGGING START-------------\")\n",
        "print(f\"Connecting to Azure SQL metadata table\")\n",
        "\n",
        "tables = pd.read_sql(\n",
        "    '''SELECT \n",
        "\t[TABLE_ID] AS [ID]\n",
        "\t,[TABLE_NAME]\n",
        "\t,[SOURCE_SYSTEM]\n",
        "\t,[EXTRACTION_TYPE]\n",
        "\t,[IS_ACTIVE]\n",
        "\t,'SAP TABLE' AS [CONNECTOR_TYPE]\n",
        "FROM [MDL].[EXTRACTION_SAPTABLE]\n",
        "WHERE [IS_ACTIVE] = '1'\n",
        "AND TABLE_NAME in ('EKET','EKKO','EKPO','EKES')\n",
        "\t'''\n",
        "    ,cnxn\n",
        ")\n",
        "\n",
        "distinct_tables = tables['TABLE_NAME'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Load data in temporary views"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Set timezone\n",
        "timezone = pytz.timezone('Europe/Amsterdam')\n",
        "\n",
        "# Loop over tables\n",
        "for table in distinct_tables:\n",
        "    table_name = table.lower()\n",
        "\n",
        "    # Set start Timestamp\n",
        "    ts_start = datetime.now(tz = timezone)\n",
        "\n",
        "    # Logging\n",
        "    print(f\"-------------------------\")\n",
        "    print(f\"Source table: {table_name} from source system {source} is started at {ts_start}\")\n",
        "    \n",
        "    # execute the function\n",
        "    load_delta_data_in_temp_views(source, source_container, storageaccount, table_name)\n",
        "\n",
        "    # Reset end Timestamp\n",
        "    ts_end = datetime.now(tz = timezone)\n",
        "\n",
        "    # Logging end\n",
        "    print(f\"Source table: {table_name} is finished at {ts_end}\")\n",
        "\n",
        "# Logging end\n",
        "print(f\"-------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Block to modularize code in notebooks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# referencing a notebook is giving an error in the synapse pipeline. \n",
        "# %run Delta Lakehouse/Custom package/Spark SQL/nb_SparkSQL_for_FACT_110_ORDER_BALANCE_AND_115_INCOMING_ORDERS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "print(f\"-------------------------\")\n",
        "print(f\"Starting the custom Spark SQL\")\n",
        "df = spark.sql(\n",
        "\"\"\"SELECT * FROM TEMP.VIEW\n",
        "\"\"\")\n",
        "print(f\"The custom Spark SQL successfully finised\")\n",
        "print(f\"-------------------------\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Write data to delta tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "#Global Unmanaged/External Table\n",
        "write_to_delta_table(df, source, destination_container, destination_table_name, storageaccount)\n",
        "print(f\"-------------------------\")\n",
        "print(f\"------------LOGGING END-------------\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.7.3 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.3"
    },
    "save_output": true,
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
